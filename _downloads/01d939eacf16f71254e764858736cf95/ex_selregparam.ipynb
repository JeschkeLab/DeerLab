{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysing the selection of regularisation parameter\n\nThis example demonstates how to generate plots from the regularisation parameter selection,\nand how to use this infomation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport deerlab as dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# File location\npath = '../data/'\nfile = 'example_4pdeer_1.DTA'\n\n# Experimental parameters\ntau1 = 0.3      # First inter-pulse delay, \u03bcs\ntau2 = 4.0      # Second inter-pulse delay, \u03bcs\ntmin = 0.1      # Start time, \u03bcs\n\n# Load the experimental data\nt,Vexp = dl.deerload(path + file)\n\n# Pre-processing\nVexp = dl.correctphase(Vexp) # Phase correction\nVexp = Vexp/np.max(Vexp)     # Rescaling (aesthetic)\nt = t - t[0]                     # Account for zerotime\nt = t + tmin   \n\n# Distance vector\nr = np.linspace(1.5,7,50) # nm\n\n# Construct the model\nVmodel = dl.dipolarmodel(t,r, experiment=dl.ex_4pdeer(tau1,tau2, pathways=[1]))\n\n# Fit the model to the data with compactness criterion\nresults= dl.fit(Vmodel,Vexp,regparam='bic')\nprint(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The regularisation parameter in DeerLab can be selected using a variety of criteria. \nThe default criterion is the Akaike complexity criterion (aic) however other \ncriterion exists and can be selected.\n\nEach criterion has its own functional, which is minimised. These functionals \nare often based on the residuals of the fit vs the raw data, such that a minimal functional value\nwill occur at the location of the best fit. Some methods such as the L-Curve-based methods do not follow this approach.\n\nTraditionally the L-Curve has been used to investigate and select the regularisation parameter. \nThe L-Curve is a plot of the Residual Norm against the Penalty Norm. Each point represents a \ndifferent regularisation parameter. Normally the optimal regularisation parameter can be found at the kink\nof the curve, i.e. the place that has both a low Residual Norm and a low Pentalty Norm.\nRecently, this approach has taken a back foot as the existence of an L-shape or kink is not guaranteed. \nNonetheless, it can be useful to diagnose problems in the selection of the regularisation parameter. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs =plt.subplots(1,3, figsize=(9,4),width_ratios=(1,1,0.1))\nalphas = results.regparam_stats['alphas_evaled'][1:]\nfuncs = results.regparam_stats['functional'][1:]\n\n\nidx = np.argsort(alphas)\n\naxs[0].semilogx(alphas[idx], funcs[idx],marker='.',ls='-')\naxs[0].set_title(r\"$\\alpha$ selection functional\");\naxs[0].set_xlabel(\"Regularisation Parameter\")\naxs[0].set_ylabel(\"Functional Value \")\n\n# Just the final L-Curve\n\ncmap = plt.get_cmap('plasma')\nimport matplotlib as mpl\n\nx = results.regparam_stats['residuals']\ny = results.regparam_stats['penalties']\nidx = np.argsort(x)\n\n\naxs[1].loglog(x[idx],y[idx])\n\nn_points = results.regparam_stats['alphas_evaled'].shape[-1]\nlams = results.regparam_stats['alphas_evaled']\nnorm = mpl.colors.LogNorm(vmin=lams[1:].min(), vmax=lams.max())\nfor i in range(n_points):\n    axs[1].plot(x[i], y[i],marker = '.', ms=8, color=cmap(norm(lams[i])))\n\ni_optimal = np.argmin(np.abs(lams - results.regparam))\naxs[1].annotate(fr\"$\\alpha =$ {results.regparam:.2g}\", xy = (x[i_optimal],y[i_optimal]),arrowprops=dict(facecolor='black', shrink=0.05, width=5), xytext=(20, 20),textcoords='offset pixels')\nfig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),cax=axs[2])\naxs[1].set_ylabel(\"Penalties\")\naxs[2].set_ylabel(\"Regularisation Parameter\")\naxs[1].set_xlabel(\"Residuals\")\naxs[1].set_title(\"L-Curve\");\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Over and Under selection of the regularisation parameter\nHere we will demonstrate the effect of selecting a regularisation parameter\nthat is either too small or too large. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result_high= dl.fit(Vmodel,Vexp,regparam=1.0)\n\nresult_low= dl.fit(Vmodel,Vexp,regparam=1e-4)\n\ngreen = '#3cb4c6'\nred = '#f84862'\nfig, axs =plt.subplots(1,2, figsize=(9,4),width_ratios=(1,1))\nfig.tight_layout()\n\naxs[0].set_xlabel(\"Time $t$ (\u03bcs)\")\naxs[0].set_ylabel('$V(t)$ (arb.u.)')\naxs[0].plot(t,Vexp,'.',color='grey',label='Data')\naxs[0].plot(t,result_high.model,linewidth=3,color=green,label='High regparam')\naxs[0].plot(t,result_low.model,linewidth=3,color=red,label='Low regparam')\naxs[0].legend(frameon=False,loc='best')\n\nPfit_h = result_high.P\nPci95_h = result_high.PUncert.ci(95)\n\nPfit_l = result_low.P\nPci95_l = result_low.PUncert.ci(95)\n\n\n\naxs[1].plot(r,Pfit_h,linewidth=3,color=green,label='High regparam')\naxs[1].fill_between(r,Pci95_h[:,0],Pci95_h[:,1],alpha=0.3,color=green,linewidth=0)\naxs[1].plot(r,Pfit_l,linewidth=3,color=red,label='Low regparam')\naxs[1].fill_between(r,Pci95_l[:,0],Pci95_l[:,1],alpha=0.3,color=red,linewidth=0)\naxs[1].set_ylim(0,max([Pfit_h.max(),Pfit_l.max()]))\naxs[1].legend(frameon=False,loc='best')\naxs[1].set_xlabel('Distance $r$ (nm)')\naxs[1].set_ylabel('$P(r)$ (nm$^{-1}$)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see when the regularisation parameter is too small we still get a high\nquality fit in the time domain, however, our distance domain data is now way too\nspikey and non-physical. \nIn contrast when the regularisation parameter is too large we struggle to get\na good fit, however, we get a much smoother distance distribution.\nThis could have been seen from the selection functional above. The effect of\nlower regularisation parameter had a smaller effect on the functional than the \neffect of going to a larger one. \n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}